# Imporing all required libraries

# Basic Data manupulation
import pandas as pd
import numpy as np

# Visualization
import seaborn as sns
import matplotlib.pyplot as plt

# Date related functions
import datetime
import os

# Stats
from scipy import stats
from scipy.stats import skew, norm
from scipy.special import boxcox1p
from scipy.stats import boxcox_normmax

# Machine learning Models for classification techniques
from sklearn.model_selection import GridSearchCV
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import AdaBoostClassifier,RandomForestClassifier
from xgboost import XGBClassifier
import lightgbm as lgb

# Sampling 
from imblearn.over_sampling import SMOTE

# Reading the given data as pandas dataframes
train = pd.read_csv('Train.csv')
test = pd.read_csv('Test.csv')

#Exploratory Data Analysis

# Checking the dimension of the train data
train.shape

#The training data has only 16 columns and 6439 rows that is considerably less amount of data provided to us for training our machine learning models, hence we will have to create a cross validation mechanism for checking the efficiency of a model built

# Checking the dimension of the test data
test.shape

#The test data has 2676 rows that would provide enough data for validating the results of our analysis using the train data

# Taking a look at the training data
train.head()


#From the initial glance at the given data we can notice a few things :

#1. "Date of Creation" and "Actual Date of Completion" columns need to be converted to a proper date format
#2. We can create another columns for time factor in "Date of Creation" and "Actual Date of Completion" for analysing if the time also plays a role in deciding the output
#3. "Street type" column should not be a float value as it only signifies that the street is uphill or downhill
#4. "A_1" and "A_2" columns look exactly same
#We will further analyse these assumptions and manupulate the data accordingly, but first we should have a look at the testing data as well

# Taking a look at the test data
test.head()

#The assumptions took while having a look at the training data are also present in the training data however we can also see that there is a NaN value present in the data, hence we would check the missing values present in both train and test data

# Checking the missing values in training data
train.isna().sum().sort_values(ascending = False).head()

#As we can see there are null or missing values in 2 columns i.e Actual Date of Completion and Street Type column. Assumptions:

#1. We would assume that where Actual Date of Completion column is null , there the project is yet to be completed or not completed
#2. For null values in Street Type column, we would like to assume that the slanting property of that street is not available to us, hence we would have to further analyse by which method we can impute the missing values in order to increase the efficiency of our predictions

# Checking the missing values in test data
test.isna().sum().sort_values(ascending = False).head()

#There are again missing values present in the data in columns : Actual Date of Completion, Street Type and Estimated Date of Completion

#1. For the 2 columns similar to the training data we would continue to have the same assumptions, however for the column "Estimated Date of Completion" we would have to further analyse the data available.
 #   1. Firstly we will have to check if the rows where "Estimated Date of Completion" is null, there the column "Actual Date of Completion" is present or not , on the basis of that we can further make a conclusion that is it a data entry miss or we don't have the clarity on when that particular model is going to end.

## Converting the datatypes of the columns to required format

# converting Object to date
train["Date of Creation"] = pd.to_datetime(train["Date of Creation"]).dt.normalize()
train["Actual Date of Completion"] = pd.to_datetime(train["Actual Date of Completion"]).dt.normalize()
train["Estimated Date of Completion"] = pd.to_datetime(train["Estimated Date of Completion"]).dt.normalize()

# First we will check and impute missing values for Actual Date of Completion column
sns.countplot(x='Actual Date of Completion',data=train)

#As we can see there is no clear pattern in the data however we can see that some values are comparitively much higher than the others while there are some values extremely low and close to 0, they might be outliers but as this is a date column we would rather move ahead with the given data itself For imputing the missing values we should give the values as "Not available"

# Next I would like to move on to street type column
train["Street Type"].value_counts()
sns.countplot(x='Street Type',data=train)

# As there is no trend in the given data we will impute the values with '0'
train["Street Type"] = train["Street Type"].fillna(0)
test["Street Type"] = test["Street Type"].fillna(0)

# Converting float to Int
train['Street Type'] = train['Street Type'].astype(int)

train.dtypes

# Checking if each row has a unique id
print(len(train['L_Id']))
print(len(train['L_Id'].unique()))

# Let us check how the independent variables are linked to the dependent(target) variable
corrmat = train.corr()
f, ax = plt.subplots(figsize=(12, 10))
sns.heatmap(corrmat, vmax=.8,cmap="Blues", square=True);

#Validating our initial assumption that A_1 and A_2 columns are exactly same because of 100% correlation, we can safely remove any one column from the analysis

# Dropping A_1 column from both test and train data
train.drop(["A_1"], axis = 1, inplace = True)
test.drop(["A_1"], axis = 1, inplace = True)

## Checking the importance of each variable by checking correlation with the target variable
plt.figure(figsize=(3,12))
sns.heatmap(train.corr()[['Problem Category']].sort_values(by=['Problem Category'],ascending=False).head(50), vmin=-1, annot=True);

## Checking for outliers in the data

int_variable_list=['Agent Category Assigned','Type of Request','Description of the Request','Location','Region Type','Ward No','Request Solution Category','Team Assigned','A_2']

z_score_calc = train[int_variable_list]
# Calculating z score
z = np.abs(stats.zscore(z_score_calc))
# print(z)
print(np.where(z > 4))

#There are no significant outliers present in the given data

## Checking the skewness of the numeric columns
# Create box plots for all numeric features
sns.set_style("white")
f, ax = plt.subplots(figsize=(8, 7))
ax.set_xscale("log")
ax = sns.boxplot(data=train[int_variable_list] , orient="h", palette="Set1")
ax.xaxis.grid(False)
ax.set(ylabel="Feature names")
ax.set(xlabel="Numeric values")
ax.set(title="Numeric Distribution of Features")
sns.despine(trim=True, left=True)

# Find skewed numerical features
skew_features = train[int_variable_list].apply(lambda x: skew(x)).sort_values(ascending=False)

# Features with high skewness
high_skew = skew_features[skew_features > 0.5]
skew_index = high_skew.index

print("There are {} numerical features with Skew > 0.5 :".format(high_skew.shape[0]))
skewness = pd.DataFrame({'Skew' :high_skew})
skew_features.head(10)

## Checking the target variable distribution
print(train['Problem Category'].value_counts())
plt.figure(figsize=(10,10))
plt.xticks(rotation=90)
plt.title('Distribution of Target Variable')
sns.countplot(x='Problem Category',data=train)

#As we can see the target distribution is highly skewed towards the value 1, hence we will have to sample the training data differently in order to have a balanced dataset and then the model will be able to predict the values correctly

# Modelling


# Creating the variables for model fitting
X = train[int_variable_list]
y = train['Problem Category']

# Test variable
test = test.drop(columns=['L_Id'])

## Splitting the training data to traina and validation test set
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y,test_size = .3, random_state=0)

## Oversampling using SMOTE to make a balanced dataset before proceeding with Modelling
print("Before OverSampling, counts of label '2': {}".format(sum(y_train == 2)))
print("Before OverSampling, counts of label '1': {}".format(sum(y_train == 1))) 
print("Before OverSampling, counts of label '0': {} \n".format(sum(y_train == 0))) 
 
sm = SMOTE(random_state = 3) 
X_train_res, y_train_res = sm.fit_sample(X_train, y_train.ravel()) 
  
print('After OverSampling, the shape of train_X: {}'.format(X_train_res.shape)) 
print('After OverSampling, the shape of train_y: {} \n'.format(y_train_res.shape)) 
  
print("After OverSampling, counts of label '2': {}".format(sum(y_train_res == 2))) 
print("After OverSampling, counts of label '1': {}".format(sum(y_train_res == 1))) 
print("After OverSampling, counts of label '0': {}".format(sum(y_train_res == 0)))

## Modelling
## Using Random Forest Model to predict the target value on test data
## This line instantiates the model. ## This  
rf = RandomForestClassifier() 
## Fit the model on training data.
rf.fit(X_train_res, y_train_res) 
## And score it on validation data.
rf.score(X_test, y_test)

## Predicting on the test dataset
test = pd.read_csv('Test.csv')
test_for_pred = test[int_variable_list]
prediction_rf = rf.predict(test_for_pred)

## Creating the output dataset
df_rf=pd.DataFrame()
df_rf['L_Id']=test['L_Id']
df_rf['Problem Category']=prediction_rf


## LightGBM classifier
lgbc = lgb.LGBMClassifier(learning_rate = 0.125, 
                        n_estimators = 20, num_leaves = 38)
lgbc.fit(X_train_res, y_train_res) 
lgbc.score(X_test, y_test)

## Predicting on the test dataset
prediction_lgb = lgbc.predict(test_for_pred)

## Creating the output dataset
df_lgb=pd.DataFrame()
df_lgb['L_Id']=test['L_Id']
df_lgb['Problem Category']=prediction_lgb

## XGBoost Classifier
xgbc = XGBClassifier()
xgbc.fit(X_train_res, y_train_res) 
xgbc.score(X_test, y_test)

## Predicting on the test dataset
prediction_xgb = xgbc.predict(test_for_pred)

## Creating the output dataset
df_xgb=pd.DataFrame()
df_xgb['L_Id']=test['L_Id']
df_xgb['Problem Category']=prediction_xgb

# Blend models on the basis of their accuracy in order to make the final predictions more robust to overfitting
def blended_predictions(X):
    return (((0.3 * rf.predict(X)) + \
            (0.3 * lgbc.predict(X)) + \
            (0.4 * xgbc.predict((X)))))

## Predicting on the test dataset
final_predictions  = blended_predictions(test_for_pred)

## Creating the output dataset
df_blended=pd.DataFrame()
df_blended['L_Id']=test['L_Id']
df_blended['Problem Category']=final_predictions


#If 'df' is the dataframe containing your predictions and no feature column is for index:
df_blended.to_csv('submission.csv', index=False)
